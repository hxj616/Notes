Download this paper: https://www.ijcai.org/proceedings/2023/0549.pdf

# GPMO: Gradient Perturbation-Based Contrastive Learning for Molecule Optimization 面向分子优化的基于梯度扰动的对比学习

## Abstract

基于翻译的方法 (translation-based methods) 在新药设计中，可以优化特定性质的分子，但是面临着**曝光偏差**的问题。

- **exposure bias**，曝光偏差，即训练数据和实际应用中的数据并不完全一致

为了避免曝光偏差，需要在对比学习中使用positive molecules (理想分子) 和 negative molecules (非理想分子)。但是生成合适的 positive molecules 需要特定领域的知识，而随机选取的 negative molecules 很容易与 real molecules 区分开来，这使得问题更加复杂。

GPMO方法，即面向分子优化的基于梯度扰动的对比学习，可以防止曝光偏差的发生。这种方法可以有效地处理真实分子和人工生成的分子，并通过正负样本的辅助来提高模型的**鲁棒性**。

- **robustness**，鲁棒性，指模型在面对噪声、数据分布变化或意料之外的输入时，仍然能够保持良好性能的能力

## 1   Introduction

分子优化 (Molecule Optimization MO)，旨在识别目标分子，该分子在保持其与原始分子的相似性的同时，表现出改进的药理学特性。

传统上，化学家依靠知识、经验与直觉进行MO。这种手动的方法耗时、耗力，并且可能无法探索一个分子的所有增强药理学特性的可能。

计算机进行模拟MO，进行自动化处理来提升分子的药理学特性，目前进行了一系列研究，这些研究存在着问题。

在训练阶段，DGM（深度生成模型）方法依赖 **Teacher-Forcing** 策略，模型只学习到正确的上下文。而在测试阶段，模型需要根据自己预测的结果来进行后续预测，这会导致与训练时的上下文不一致，即 exposure bias 曝光偏差问题。

- **Teacher-Forcing**，教师强制，一种训练技术，常用于序列生成任务中。在标准的序列生成模型中，模型在生成序列时需要逐步预测下一个词或字符。在 Teacher-Forcing 策略中，模型的每一步训练过程不依赖它自己上一步的预测结果，而是直接使用训练数据中真实的下一个词或字符。这种策略使得训练过程更加稳定，模型不会因为前面某一步的错误预测导致后续预测的级联错误。**这会导致测试时模型的表现与训练时不一致，因为测试时模型只能依赖它自己一步步生成的结果。**

为了应对这个问题，GPMO引入**对比学习**。

- **Contrastive learning**，对比学习，一种机器学习方法，通过对比正样本和负样本来增强模型的学习效果。

GPMO使用了两种主要的输入：

1. **Condition Tokens**，条件标记，是指用于定义优化目标或约束的标记。这些标记可以是关于分子应具备的某些特性的描述，如特定的化学性质或生物活性。
2. **SMILES** (Simplified Molecular Input Line Entry System)是一种用于表示化学分子的线性字符串表示法。它通过简单的文本字符表示分子的结构和连接方式，使得化学结构可以被计算机处理和分析。
SMILES的格式：SMILES 使用字符表示原子和化学键。例如，水（H₂O）的 SMILES 表达式是 'o'，而乙醇（C₂H₅OH）的 SMILES 表达式是 'cco'。

在GPMO中，模型通过**梯度扰动**生成正分子和负分子，

- **Gradient Perturbation**，梯度扰动，一种在机器学习和优化算法中使用的技术。在机器学习中，梯度是指损失函数对模型参数的偏导数，表示在参数空间中哪个方向可以最快地减少损失。梯度扰动是指，在计算梯度时，对梯度进行微小的修改或加上一个小的随机噪声，从而改变参数的更新方向或模型的行为。这种扰动可以用来生成新的样本，或用于增强模型的稳健性和泛化能力。

Negative molecule 生成：通过对目标分子的隐藏状态施加一个小的梯度扰动来生成。模型的训练目标是最小化这些负分子的**条件似然**，使其能够正确地分类为负样本。

- **Likelihood Function**，似然函数，在统计学和机器学习中，似然函数表示：给定模型参数，观测数据出现的概率。通常，训练模型的目标是通过调整参数，使得在已知训练数据下，似然最大化，即数据出现的概率最大。

Positive molecule 生成：通过两步梯度扰动生成正分子，使用**Kullback-Leibler散度**来确保生成的正分子与真实分子的分布相似。两步梯度扰动使正分子在**嵌入空间**远离真实分子，这会给模型带来挑战，从而使模型在对比学习中更好地学习分子的多样性和优化方向。

- **Kullback-Leibler Divergence**，KL散度，是一种用来衡量两个概率分布之间差异的非对称性度量。在信息论中，它通常用于比较一个真实分布和一个近似分布之间的距离。（下为KL散度介绍）
  - 1. **基本概念**：
    - 假设我们有两个概率分布：\( P(x) \)（真实分布）和 \( Q(x) \)（近似分布）。
    - KL 散度衡量的是，如果我们使用 \( Q(x) \) 来近似 \( P(x) \)，在信息上会损失多少。也就是说，它量化了 \( Q(x) \) 和 \( P(x) \) 之间的差异。

  - 2. **KL 散度的公式**：
    - KL 散度的数学定义如下：
      $$
      D_{KL}(P || Q) = \sum_x P(x) \log\left(\frac{P(x)}{Q(x)}\right)
      $$
      或者，在连续情况下：
      $$
      D_{KL}(P || Q) = \int P(x) \log\left(\frac{P(x)}{Q(x)}\right) dx
      $$
    
      - P(x) 是真实分布。
      - Q(x) 是近似分布。
      - log 表示对数函数（通常是自然对数）。

  - 3. **解释**：
    - **零散度**：当 \( P(x) = Q(x) \) 对所有 \( x \) 成立时，KL 散度为零，表示两个分布完全相同。
    - **非负性**：KL 散度总是非负的，即
      $$
      D_{KL}(P || Q) \geq 0
      $$
       它衡量的是从 \( Q(x) \) 到 \( P(x) \) 的信息损失或额外开销。
    - **非对称性**：KL 散度是不对称的，即
      $$
      D_{KL}(P || Q)≠D_{KL}(Q || P)
      $$
      这意味着从 \( P \) 到 \( Q \) 的信息损失与从 \( Q \) 到 \( P \) 的信息损失可能不同。
    
  - 4. **总结**：通过最小化 KL 散度，模型可以更好地逼近真实分布，使得预测或生成的数据与真实数据更加一致。
  
- **Embedding Space**，嵌入空间，指的是将高维或复杂的数据（如文本、图像或分子结构）通过模型转换为低维连续向量的空间。在这个低维空间中，相似的对象会被映射到相近的点上，而不相似的对象会被映射到较远的点上。

贡献总结：

1. GPMO是第一个通过生成正样本和负样本来解决分子优化中的“曝光偏差”问题的模型。
2. GPMO的正负样本生成策略不依赖领域特定知识，并且在**反向传播**中易于实现。
3. 实验结果显示，GPMO在优化分子属性方面达到了当前最先进的水平，同时能保持分子的基本结构。

- **Back-propagation**，反向传播，是深度学习中训练神经网络的重要算法，用于计算和传播误差，通过调整网络的权重来最小化误差，从而优化模型。

## 2   Related Work

### 2.1 Reinforcement Learning Method

RL的目标是训练智能体在环境中采取行动，以最大化累计奖励。在分子优化中，环境由化学规则定义，分子性质的改进被定义为RL中的奖励(reward)。
RL的优势：有效的性质改善；能在更大的化学空间中运行。
RL的挑战：会使分子结构过于复杂。
新开发的RL方法引入了合成树（synthesis tree）。通过在合成树中遵循一定的路径，确保优化后的分子结构是可合成的。

### 2.2 Deep Generative Model

在分子优化中，DGM将一个起始分子作为输入，并生成一个目标分子作为输出。目标分子通常比起始分子更具药物性质。

### 2.3 Hybrid Method

  1. Genetic Algorithm，遗传算法。
  2. Markov Chain Monte Carlo，马尔科夫链蒙特卡洛方法。
  3. Bayesian Optimization，贝叶斯优化。

这项工作提出了一种新颖的分子优化方法，将分子优化视为机器翻译问题，利用对比学习生成正负分子。

## 3   Method

GPMO的具体内容：

   1. encoder-decoder的预训练
   2. 具有对比学习的条件分子优化

条件分子优化包括：

   1. condition tokens 条件标记
   2. 起始分子的SMILES作为encoder-decoder模型的输入，输出是目标分子的SMILES。

负样本通过负扰动生成，从研究结果来看，负样本的SMILES字符串与起始分子相似，但由于修改了单个token，导致上下文发生变化，生成的分子可能是无效的，在化学结构上不合理。

正样本通过正扰动生成，正样本的SMILES字符串与起始分子不同，但他们与起始分子有着相似的化学结构。因此正样本在化学性质上与起始分子更接近。

### 3.1 Problem Definition

分子优化是一个**seq2seq**问题，其将起始分子的SMILES翻译成目标分子的SMILES。

- **seq2seq**，sequence-to-sequence problem，是一类用于将一个序列映射到另一个序列的机器学习问题。

这个训练通过编码器-解码器模型将一个起始分子的序列转化为目标分子的序列。训练过程使用教师强制的自回归解码，通过训练数据的最大似然估计（MLE）来优化模型的参数。

### 3.2 Condition Token

GPMO方法用于在给定的条件下优化分子，从起始分子转换为符合目标要求的分子，同时保持两者的结构相似性。条件分子优化是通过引入条件标记实现的。具体来说，这些标记引导了优化过程，使生成的分子满足特定的理化性质变化。

1. MMP关系：起始分子和目标分子需要遵循 MMP (Matched Molecular Pair 匹配分子对)，即两者必须具有相同的分子骨架，仅在某个化学结构上有所不同。这种约束保证了分子在结构上的相似性。
2. Conditional Tokens：条件标记用来编码起始分子与目标分子的性质差异，从而引导优化过程生成符合要求的分子。这些标记包含了起始分子与目标分子的性质变化信息。

三个**ADMET属性**用于优化：

1. LogD：化合物在特定pH下的分配系数。
2. Solubility：物质在水中的溶解度。
3. Clint：肝脏内源性清除率，表示化合物在肝脏中的代谢清除能力。

属性的变化被定义为起始分子和目标分子之间某个属性的差值Δ，这些差值会被映射到一个编码表中。

- **ADMET**：用于描述药物在生物体内行为的一系列特征，代表药物研发过程中需要重点考虑的几个方面。

GPMO不仅能够针对某个特定属性进行优化，还能在保持其他属性不变或降低的情况下选择性地优化某个属性。这种多属性优化是通过条件标记来控制的，即指定哪些属性应该变化，哪些属性应该保持不变。

### 3.3 Positive and Negative Molecules Generation

为了不使用特定领域的知识来生成对抗学习用到的负分子和正分子，用到了两种梯度扰动。

1. 一种小的负扰动，生成一个与真实分子相近的负分子。            
   - 针对负扰动d，模型的优化目标是最小化与其相关的对数似然，这意味着模型应当尽量减少负扰动对模型输出的影响，保持输出的稳定性。
   - （一串不是很懂的公式）

2. 一种大的正扰动，包括了两步，生成一个与真实分子差别很大的正分子。

   - 第一步扰动：the gradient with respect to constrastive loss，此扰动的目标是，最大化配对分子之间的相似性，最小化非配对分子之间的相似性。

     通过此扰动，模型可以学习到真实分子的表示，这个过程的结果是得到一个 intermediate postive molecule。

   - 第二步扰动：KL loss，KL损失衡量了两个分布的差异，通过最小化这个损失，可以保证生成的中间分子与真实分子在分布上尽量相似。

     然后基于KL损失的梯度，进行第二次正向扰动，最终生成另一个正向分子。

对比学习是为了学习分子的潜在表示，通过配对分子和非配对分子，模型可以区分相似和不相似的分子。

对比损失（Constrastive Loss）定义如下
$$
\mathcal L_{\text{cont}(\theta)} = \sum_{i=1}^N \log \frac{\exp(\cos(z_x^i, z_y^i)/ \tau)}{\sum_{z_y^j \in S^i} \exp(\cos(z_x^i, z_y^j)/ \tau)}
$$


### 3.4 Self-Supervised Pre-Training



## 4   Experiment

### 4.1 Experiment Setup



### 4.2 Muti-Property Optimization



### 4.3 Model Performance on Smaller Datasets



### 4.4 Sensitivity Analysis



### 4.5 Multi-Step Molecule Optimization



## 5   Conclusion
